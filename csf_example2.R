# Author: Jingyang (Judy) Zhang
# Date: Nov. 5th, 2025
# Purpose: an example of building causal survival forest targeting a Restricted Mean Survival Time (RMST) with maximum follow-up time set to `horizon`.


library(tidyverse)
library(grf)

# Train a causal survival forest targeting a Restricted Mean Survival Time (RMST)
# with maximum follow-up time set to `horizon`.
n <- 2000
p <- 5
X <- matrix(runif(n * p), n, p) # Has n rows and p columns. 
W <- rbinom(n, 1, 0.5)
horizon <- 1
failure.time <- pmin(rexp(n) * X[, 1] + W, horizon)
# rexp(n): 
## Generates n independent Exponential(1) random variables.
## Each element is a positive random number representing a "baseline failure time".
# rexp(n) * X[,1]:
## Elementwise multiplication.
## X[,1] is the first column of X matrix, which is a vector of length n.
## Each exponential sample generated by rexp(.) is scaled by X[,1].
### Units with larger X[,1] values will have longer expected failure times (since multiplying by a number between 0 and 1 scales the exponential time down).
# rexp(n) * X[,1] + W:
## Adds W, a vector of 0s and 1s.
## Each individual's failure time is shifted upward by 0 or 1, depending on W. 
## If W is interpreted as a treatment, then:
### treated units (W = 1) have a slightly longer failure time than untreated (W = 0), all else equal. 
#pmin(..., horizon):
## pmin takes the elementwise minimum between the calculated failure time and horizon. 
## This censors failure time at horizon.
## Example: if horizon = 1, and rexp(n)*X[,1] + W = 1.2, then the final failure.time = 1.

censor.time <- 2 * runif(n)
Y <- pmin(failure.time, censor.time)
D <- as.integer(failure.time <= censor.time) 
## If failure.time <= censor.time: event occured before censoring, event indicator D = 1.
## If failure.time > censor.time: event has not occured before censoring, event indicator D = 0.

# Save computation time by constraining the event grid by discretizing (round) continuous events.
## Or do so more flexibly by defining your own time grid using the failure.times argument:
### grid <- seq(min(Y), max(Y), length.out = 150).
### cs.forest <- causal_survival_forest(X, Y, W, D, horizon = horizon, failure.times = grid).
cs.forest <- causal_survival_forest(X, round(Y, 2), W, D, horizon = horizon)

# round(Y,2): rounding to 2 decimal places (hundredths).


# Predicting using the forest.

## Predict on new data. 
X.test <- matrix(0.5, 10, p)
X.test[,1] <- seq(0, 1, length.out = 10)
cs.pred <- predict(cs.forest, X.test)

## Predict on out-of-bag training samples.
cs.pred <- predict(cs.forest)

## Predict with confidence intervals on new data.
### Growing more trees is now recommended. 
cs.pred <- predict(cs.forest, X.test, estimate.variance = TRUE)

# Comnpute a doubly robust estimate of the average treatment effect.
average_treatment_effect(cs.forest)

# Compute the best linear projection on the first covariate. 
best_linear_projection(cs.forest, X[,1])

# Compute the best linear projection on the all 5 covariates. 
best_linear_projection(cs.forest, X)


# See if a causal survival forest succeeded in capturing heterogeneity by plotting the TOC and calculating a 95% CI for the AUTOC. 

train <- sample(1:n, n / 2) # 1000 observations.
eval <- -train # 1000 observations.
# Using a negative index will excludes those indices when subsetting. 
## -train creates a vector of negative indicies corresponding to all the numbers in train. 
## X[-train,] = X[eval,] will return all elements of X except those at positions in train. 


# Fit a CSF on the training set, estimating individual treatment effects for survival outcomes. 
train.forest <- causal_survival_forest(X[train,], Y[train], W[train], D[train], horizon = horizon)

# Fit a CSF on the evaluation set, estimating individual treatment effects for survival outcomes. 

eval.forest <- causal_survival_forest(X[eval,], Y[eval], W[eval], D[eval], horizon = horizon)


rate <- rank_average_treatment_effect(eval.forest,
                                      predict(train.forest, X[eval,])$predictions)

# predict(): applies the trained CSF to the evaluation covariates. 
## This gives predicted individual treatment effects (e.g., estimated survival benefit from treatment) for the evaluation set. 
## predict(train.forest, X[eval,]$predictions gives a vector of these estimated ITEs. 

# rank_average_treatment_effect(): evaluates how well the predicted treatment effects rank the actual observed effects in the evaluation set. 
## Specifically:
### eval.forest contains the actual outcomes for the evaluation set, used to compute observed effects. 
### predict(train.forest, X[eval,]$predictions contains predicted ITEs from the training forest. 
## This function returns a rate or ranking metric that measures whether individuals predicted to benefit more from treatment actually do benefit more. 
## Essnetially, this is an out-of-sample validation of your ITE predictions: it tells you whether the ordering of predicted effects aligns with observed effects. 
## Summary:
### train.forest -> trained on half the data. 
### predict(train.forest, X[eval,]) -> use the trained CSF to predict ITEs on the other half of the data. 
### rank_average_treatment_effect() -> checks if those predicted ITEs correctly rank the individual's true treatment effects in the evaluation set. 
## The resulting rate is like a ranking-based performance metric for heterogeneous treatment effect predictions. 


plot(rate)


paste("AUTOC:", round(rate$estimate, 2), "+/-", round(1.96 * rate$std.err, 2))
